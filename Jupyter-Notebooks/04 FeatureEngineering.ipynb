{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspace/fraud-analysis/Jupyter-Notebooks'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You set a new current directory\n"
     ]
    }
   ],
   "source": [
    "os.chdir(os.path.dirname(current_dir))\n",
    "print(\"You set a new current directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspace/fraud-analysis'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (2.2.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Transaction ID</th>\n",
       "      <th>Customer ID</th>\n",
       "      <th>Transaction Amount</th>\n",
       "      <th>Transaction Date</th>\n",
       "      <th>Payment Method</th>\n",
       "      <th>Product Category</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Customer Age</th>\n",
       "      <th>Customer Location</th>\n",
       "      <th>Device Used</th>\n",
       "      <th>IP Address</th>\n",
       "      <th>Shipping Address</th>\n",
       "      <th>Billing Address</th>\n",
       "      <th>Is Fraudulent</th>\n",
       "      <th>Account Age Days</th>\n",
       "      <th>Transaction Hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bee23c75-f691-45c0-9b0b-6a598ac7f813</td>\n",
       "      <td>d160690c-cb95-4478-8029-962b82d049da</td>\n",
       "      <td>127.50</td>\n",
       "      <td>2024-03-21 14:39:53</td>\n",
       "      <td>PayPal</td>\n",
       "      <td>clothing</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>Pamelaton</td>\n",
       "      <td>tablet</td>\n",
       "      <td>188.234.250.80</td>\n",
       "      <td>3852 Stephens Drive Apt. 885\\nNorth Vincent, O...</td>\n",
       "      <td>3852 Stephens Drive Apt. 885\\nNorth Vincent, O...</td>\n",
       "      <td>0</td>\n",
       "      <td>104</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e95ced5c-b5a3-4242-882c-0c66cc3fa02c</td>\n",
       "      <td>6008170d-8234-4bb1-aec4-942c8144a8e6</td>\n",
       "      <td>68.19</td>\n",
       "      <td>2024-03-14 07:03:19</td>\n",
       "      <td>debit card</td>\n",
       "      <td>health &amp; beauty</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>Michaeltown</td>\n",
       "      <td>mobile</td>\n",
       "      <td>119.123.16.136</td>\n",
       "      <td>309 Johnson Dale\\nSouth Vanessa, CT 82952</td>\n",
       "      <td>309 Johnson Dale\\nSouth Vanessa, CT 82952</td>\n",
       "      <td>0</td>\n",
       "      <td>258</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ca8c7221-b11a-406a-ba6c-adc57fd3f639</td>\n",
       "      <td>4aa12f35-6373-48d2-937d-bf47214b25ce</td>\n",
       "      <td>73.27</td>\n",
       "      <td>2024-03-09 09:37:13</td>\n",
       "      <td>credit card</td>\n",
       "      <td>clothing</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>North Christinaburgh</td>\n",
       "      <td>tablet</td>\n",
       "      <td>199.166.229.255</td>\n",
       "      <td>231 Thornton Point\\nEast Stephanie, DC 39033</td>\n",
       "      <td>231 Thornton Point\\nEast Stephanie, DC 39033</td>\n",
       "      <td>0</td>\n",
       "      <td>114</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Transaction ID                           Customer ID  \\\n",
       "0  bee23c75-f691-45c0-9b0b-6a598ac7f813  d160690c-cb95-4478-8029-962b82d049da   \n",
       "1  e95ced5c-b5a3-4242-882c-0c66cc3fa02c  6008170d-8234-4bb1-aec4-942c8144a8e6   \n",
       "2  ca8c7221-b11a-406a-ba6c-adc57fd3f639  4aa12f35-6373-48d2-937d-bf47214b25ce   \n",
       "\n",
       "   Transaction Amount     Transaction Date Payment Method Product Category  \\\n",
       "0              127.50  2024-03-21 14:39:53         PayPal         clothing   \n",
       "1               68.19  2024-03-14 07:03:19     debit card  health & beauty   \n",
       "2               73.27  2024-03-09 09:37:13    credit card         clothing   \n",
       "\n",
       "   Quantity  Customer Age     Customer Location Device Used       IP Address  \\\n",
       "0         1            25             Pamelaton      tablet   188.234.250.80   \n",
       "1         2            26           Michaeltown      mobile   119.123.16.136   \n",
       "2         2            44  North Christinaburgh      tablet  199.166.229.255   \n",
       "\n",
       "                                    Shipping Address  \\\n",
       "0  3852 Stephens Drive Apt. 885\\nNorth Vincent, O...   \n",
       "1          309 Johnson Dale\\nSouth Vanessa, CT 82952   \n",
       "2       231 Thornton Point\\nEast Stephanie, DC 39033   \n",
       "\n",
       "                                     Billing Address  Is Fraudulent  \\\n",
       "0  3852 Stephens Drive Apt. 885\\nNorth Vincent, O...              0   \n",
       "1          309 Johnson Dale\\nSouth Vanessa, CT 82952              0   \n",
       "2       231 Thornton Point\\nEast Stephanie, DC 39033              0   \n",
       "\n",
       "   Account Age Days  Transaction Hour  \n",
       "0               104                14  \n",
       "1               258                 7  \n",
       "2               114                 9  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train_set_path = \"outputs/datasets/clean_data/TrainSetClean.csv\"\n",
    "TrainSet = pd.read_csv(train_set_path)\n",
    "TrainSet.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m test_set_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutputs/datasets/clean_data/TestSetClean.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      2\u001b[0m TestSet \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(test_set_path)\n\u001b[0;32m----> 3\u001b[0m TestSet \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIP Address\u001b[39m\u001b[38;5;124m'\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      4\u001b[0m TestSet\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m3\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "test_set_path = 'outputs/datasets/clean_data/TestSetClean.csv'\n",
    "TestSet = pd.read_csv(test_set_path)\n",
    "TestSet = df.drop('IP Address', axis=1)\n",
    "TestSet.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install ydata_profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ydata_profiling import ProfileReport\n",
    "pandas_report = ProfileReport(df=TrainSet, minimal=True)\n",
    "pandas_report.to_notebook_iframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install feature_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from feature_engine import transformation as vt\n",
    "from feature_engine.outliers import Winsorizer\n",
    "from feature_engine.encoding import OrdinalEncoder\n",
    "sns.set(style=\"whitegrid\")\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "def FeatureEngineeringAnalysis(df, analysis_type=None):\n",
    "    \"\"\"\n",
    "    - used for quick feature engineering on numerical and categorical variables\n",
    "    to decide which transformation can better transform the distribution shape\n",
    "    - Once transformed, use a reporting tool, like ydata-profiling, to evaluate distributions\n",
    "    \"\"\"\n",
    "    check_missing_values(df)\n",
    "    allowed_types = ['numerical', 'ordinal_encoder', 'outlier_winsorizer']\n",
    "    check_user_entry_on_analysis_type(analysis_type, allowed_types)\n",
    "    list_column_transformers = define_list_column_transformers(analysis_type)\n",
    "\n",
    "    # Loop in each variable and engineer the data according to the analysis type\n",
    "    df_feat_eng = pd.DataFrame([])\n",
    "    for column in df.columns:\n",
    "        # create additional columns (column_method) to apply the methods\n",
    "        df_feat_eng = pd.concat([df_feat_eng, df[column]], axis=1)\n",
    "        for method in list_column_transformers:\n",
    "            df_feat_eng[f\"{column}_{method}\"] = df[column]\n",
    "\n",
    "        # Apply transformers in respective column_transformers\n",
    "        df_feat_eng, list_applied_transformers = apply_transformers(\n",
    "            analysis_type, df_feat_eng, column)\n",
    "\n",
    "        # For each variable, assess how the transformations perform\n",
    "        transformer_evaluation(\n",
    "            column, list_applied_transformers, analysis_type, df_feat_eng)\n",
    "\n",
    "    return df_feat_eng\n",
    "\n",
    "\n",
    "def check_user_entry_on_analysis_type(analysis_type, allowed_types):\n",
    "    \"\"\" Check analysis type \"\"\"\n",
    "    if analysis_type is None:\n",
    "        raise SystemExit(\n",
    "            f\"You should pass analysis_type parameter as one of the following options: {allowed_types}\")\n",
    "    if analysis_type not in allowed_types:\n",
    "        raise SystemExit(\n",
    "            f\"analysis_type argument should be one of these options: {allowed_types}\")\n",
    "\n",
    "\n",
    "def check_missing_values(df):\n",
    "    if df.isna().sum().sum() != 0:\n",
    "        raise SystemExit(\n",
    "            f\"There is a missing value in your dataset. Please handle that before getting into feature engineering.\")\n",
    "\n",
    "\n",
    "def define_list_column_transformers(analysis_type):\n",
    "    \"\"\" Set suffix columns according to analysis_type\"\"\"\n",
    "    if analysis_type == 'numerical':\n",
    "        list_column_transformers = [\n",
    "            \"log_e\", \"log_10\", \"reciprocal\", \"power\", \"box_cox\", \"yeo_johnson\"]\n",
    "\n",
    "    elif analysis_type == 'ordinal_encoder':\n",
    "        list_column_transformers = [\"ordinal_encoder\"]\n",
    "\n",
    "    elif analysis_type == 'outlier_winsorizer':\n",
    "        list_column_transformers = ['iqr']\n",
    "\n",
    "    return list_column_transformers\n",
    "\n",
    "\n",
    "def apply_transformers(analysis_type, df_feat_eng, column):\n",
    "    for col in df_feat_eng.select_dtypes(include='category').columns:\n",
    "        df_feat_eng[col] = df_feat_eng[col].astype('object')\n",
    "\n",
    "    if analysis_type == 'numerical':\n",
    "        df_feat_eng, list_applied_transformers = FeatEngineering_Numerical(\n",
    "            df_feat_eng, column)\n",
    "\n",
    "    elif analysis_type == 'outlier_winsorizer':\n",
    "        df_feat_eng, list_applied_transformers = FeatEngineering_OutlierWinsorizer(\n",
    "            df_feat_eng, column)\n",
    "\n",
    "    elif analysis_type == 'ordinal_encoder':\n",
    "        df_feat_eng, list_applied_transformers = FeatEngineering_CategoricalEncoder(\n",
    "            df_feat_eng, column)\n",
    "\n",
    "    return df_feat_eng, list_applied_transformers\n",
    "\n",
    "\n",
    "def transformer_evaluation(column, list_applied_transformers, analysis_type, df_feat_eng):\n",
    "    # For each variable, assess how the transformations perform\n",
    "    print(f\"* Variable Analyzed: {column}\")\n",
    "    print(f\"* Applied transformation: {list_applied_transformers} \\n\")\n",
    "    for col in [column] + list_applied_transformers:\n",
    "\n",
    "        if analysis_type != 'ordinal_encoder':\n",
    "            DiagnosticPlots_Numerical(df_feat_eng, col)\n",
    "\n",
    "        else:\n",
    "            if col == column:\n",
    "                DiagnosticPlots_Categories(df_feat_eng, col)\n",
    "            else:\n",
    "                DiagnosticPlots_Numerical(df_feat_eng, col)\n",
    "\n",
    "        print(\"\\n\")\n",
    "\n",
    "\n",
    "def DiagnosticPlots_Categories(df_feat_eng, col):\n",
    "    plt.figure(figsize=(4, 3))\n",
    "    sns.countplot(data=df_feat_eng, x=col, palette=[\n",
    "                  '#432371'], order=df_feat_eng[col].value_counts().index)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.suptitle(f\"{col}\", fontsize=30, y=1.05)\n",
    "    plt.show()\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "def DiagnosticPlots_Numerical(df, variable):\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "    sns.histplot(data=df, x=variable, kde=True, element=\"step\", ax=axes[0])\n",
    "    stats.probplot(df[variable], dist=\"norm\", plot=axes[1])\n",
    "    sns.boxplot(x=df[variable], ax=axes[2])\n",
    "\n",
    "    axes[0].set_title('Histogram')\n",
    "    axes[1].set_title('QQ Plot')\n",
    "    axes[2].set_title('Boxplot')\n",
    "    fig.suptitle(f\"{variable}\", fontsize=30, y=1.05)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def FeatEngineering_CategoricalEncoder(df_feat_eng, column):\n",
    "    list_methods_worked = []\n",
    "    try:\n",
    "        encoder = OrdinalEncoder(encoding_method='arbitrary', variables=[\n",
    "                                 f\"{column}_ordinal_encoder\"])\n",
    "        df_feat_eng = encoder.fit_transform(df_feat_eng)\n",
    "        list_methods_worked.append(f\"{column}_ordinal_encoder\")\n",
    "\n",
    "    except Exception:\n",
    "        df_feat_eng.drop([f\"{column}_ordinal_encoder\"], axis=1, inplace=True)\n",
    "\n",
    "    return df_feat_eng, list_methods_worked\n",
    "\n",
    "\n",
    "def FeatEngineering_OutlierWinsorizer(df_feat_eng, column):\n",
    "    list_methods_worked = []\n",
    "\n",
    "    # Winsorizer iqr\n",
    "    try:\n",
    "        disc = Winsorizer(\n",
    "            capping_method='iqr', tail='both', fold=1.5, variables=[f\"{column}_iqr\"])\n",
    "        df_feat_eng = disc.fit_transform(df_feat_eng)\n",
    "        list_methods_worked.append(f\"{column}_iqr\")\n",
    "    except Exception:\n",
    "        df_feat_eng.drop([f\"{column}_iqr\"], axis=1, inplace=True)\n",
    "\n",
    "    return df_feat_eng, list_methods_worked\n",
    "\n",
    "\n",
    "def FeatEngineering_Numerical(df_feat_eng, column):\n",
    "    list_methods_worked = []\n",
    "\n",
    "    # LogTransformer base e\n",
    "    try:\n",
    "        lt = vt.LogTransformer(variables=[f\"{column}_log_e\"])\n",
    "        df_feat_eng = lt.fit_transform(df_feat_eng)\n",
    "        list_methods_worked.append(f\"{column}_log_e\")\n",
    "    except Exception:\n",
    "        df_feat_eng.drop([f\"{column}_log_e\"], axis=1, inplace=True)\n",
    "\n",
    "    # LogTransformer base 10\n",
    "    try:\n",
    "        lt = vt.LogTransformer(variables=[f\"{column}_log_10\"], base='10')\n",
    "        df_feat_eng = lt.fit_transform(df_feat_eng)\n",
    "        list_methods_worked.append(f\"{column}_log_10\")\n",
    "    except Exception:\n",
    "        df_feat_eng.drop([f\"{column}_log_10\"], axis=1, inplace=True)\n",
    "\n",
    "    # ReciprocalTransformer\n",
    "    try:\n",
    "        rt = vt.ReciprocalTransformer(variables=[f\"{column}_reciprocal\"])\n",
    "        df_feat_eng = rt.fit_transform(df_feat_eng)\n",
    "        list_methods_worked.append(f\"{column}_reciprocal\")\n",
    "    except Exception:\n",
    "        df_feat_eng.drop([f\"{column}_reciprocal\"], axis=1, inplace=True)\n",
    "\n",
    "    # PowerTransformer\n",
    "    try:\n",
    "        pt = vt.PowerTransformer(variables=[f\"{column}_power\"])\n",
    "        df_feat_eng = pt.fit_transform(df_feat_eng)\n",
    "        list_methods_worked.append(f\"{column}_power\")\n",
    "    except Exception:\n",
    "        df_feat_eng.drop([f\"{column}_power\"], axis=1, inplace=True)\n",
    "\n",
    "    # BoxCoxTransformer\n",
    "    try:\n",
    "        bct = vt.BoxCoxTransformer(variables=[f\"{column}_box_cox\"])\n",
    "        df_feat_eng = bct.fit_transform(df_feat_eng)\n",
    "        list_methods_worked.append(f\"{column}_box_cox\")\n",
    "    except Exception:\n",
    "        df_feat_eng.drop([f\"{column}_box_cox\"], axis=1, inplace=True)\n",
    "\n",
    "    # YeoJohnsonTransformer\n",
    "    try:\n",
    "        yjt = vt.YeoJohnsonTransformer(variables=[f\"{column}_yeo_johnson\"])\n",
    "        df_feat_eng = yjt.fit_transform(df_feat_eng)\n",
    "        list_methods_worked.append(f\"{column}_yeo_johnson\")\n",
    "    except Exception:\n",
    "        df_feat_eng.drop([f\"{column}_yeo_johnson\"], axis=1, inplace=True)\n",
    "\n",
    "    return df_feat_eng, list_methods_worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_engineering= [\n",
    "        'Payment Method', 'Product Category', 'Customer Location',\n",
    "        'Device Used', 'Transaction Amount', 'Quantity', 'Is Fraudulent',\n",
    "        'Account Age Days', 'Transaction Hour']\n",
    "    \n",
    "\n",
    "variables_engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_engineering = TrainSet[variables_engineering].copy()\n",
    "df_engineering.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_engineering = FeatureEngineeringAnalysis(df=df_engineering, analysis_type='ordinal_encoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the steps are: \n",
    "# 1 - create a transformer\n",
    "# 2 - fit_transform into TrainSet\n",
    "# 3 - transform into TestSet \n",
    "encoder = OrdinalEncoder(encoding_method='arbitrary', variables = variables_engineering)\n",
    "TrainSet = encoder.fit_transform(TrainSet)\n",
    "TestSet = encoder.transform(TestSet)\n",
    "\n",
    "print(\"* Categorical encoding - ordinal transformation done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
